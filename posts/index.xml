<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Dans Stuff</title>
    <link>http://danmux.com/posts/</link>
    <description>Recent content in Posts on Dans Stuff</description>
    <generator>Hugo -- gohugo.io</generator>
    
    
    
    
    <lastBuildDate>Wed, 17 Aug 2016 00:00:00 UT</lastBuildDate>
    <atom:link href="http://danmux.com/posts/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>What Golang Is and Is Not</title>
      <link>http://danmux.com/posts/what_golang_isnt/</link>
      <pubDate>Wed, 17 Aug 2016 00:00:00 UT</pubDate>
      
      <guid>http://danmux.com/posts/what_golang_isnt/</guid>
      <description>

&lt;p&gt;We are all products of our own histories, and I suspect many routes to Go have been made less enjoyable by misguided expectations. The journey from when a budding developer first &amp;lsquo;hello worlded’ to now may have made Go&amp;rsquo;s more subtle strengths less obvious to them.&lt;/p&gt;

&lt;p&gt;Go is least of all about the language in and of itself, but rather about the broader things affected by it, more so than other languages I have used over the years.&lt;/p&gt;

&lt;p&gt;Many recent arrivals to Go have preconceptions that have been proved wrong and caused disappointment, this appears to happen most often when looking from a more purist computer science based language design point of view.&lt;/p&gt;

&lt;p&gt;Go is an engineering tool, in a much broader sense. To appreciate it properly I think you have to have spent a decent amount of time responsible for the full lifecycle. If all you ever do is write and commit code then much of Go will be lost on you.&lt;/p&gt;

&lt;h2 id=&#34;the-go-hype-or-not:6f23aa5cf001e206affe126e84fac8b3&#34;&gt;The Go Hype, or Not.&lt;/h2&gt;

&lt;p&gt;I have heard more than once that people have been disappointed by go given the &lt;em&gt;hype&lt;/em&gt; surrounding it. I don’t remember anything really hype like 5 years ago when go was in its infancy, and I must say that I am not really aware of anything specific now. Of course any new language that is becoming better adopted, in particular as quickly as Go, will naturally attract attention.&lt;/p&gt;

&lt;p&gt;There are articles out there that sing Go&amp;rsquo;s praises, perhaps a little too highly, but I don&amp;rsquo;t remember many of them explicitly making any claims about the &lt;em&gt;language&lt;/em&gt; itself being the reason why Go is so good.&lt;/p&gt;

&lt;h2 id=&#34;go-is-not-an-innovative-language:6f23aa5cf001e206affe126e84fac8b3&#34;&gt;Go is Not An Innovative Language&lt;/h2&gt;

&lt;p&gt;&amp;ldquo;Innovative&amp;rdquo; is such an overused and abused word that it has lost a lot of power and meaning. All innovation is contextual and to use the word without context is foolhardy. In the context of language design Go was never an innovative language, nor was it presented as such, or anyone dishonest in representing it that way.&lt;/p&gt;

&lt;p&gt;As a language Go was always explicitly a return to simplicity, and in many ways naivety, for sound reasons.&lt;/p&gt;

&lt;p&gt;&amp;ldquo;There is nothing new under the sun&amp;rdquo; rings true in all languages since the 80&amp;rsquo;s. Virtually everything we see in language design now that someone says is &amp;ldquo;innovative&amp;rdquo; has been explored in some form before. Go is certainly no exception, but remember it never claimed to be state of the art.&lt;/p&gt;

&lt;p&gt;Regarding the language being youthful, of course it is, but the intention is not for the language itself to &amp;lsquo;mature&amp;rsquo;: no more complexity is going to be added, or at least it&amp;rsquo;s very unlikely. It is not &amp;lsquo;missing&amp;rsquo; comprehensions, or inheritance, or generics, they are &lt;strong&gt;omitted&lt;/strong&gt; (and I pray, always will be). In some way, in the context of the current fashion of returning to more functional languages, or the evolution of good old languages to include more functional paradigms (I&amp;rsquo;m looking at you Javascript and Python for two examples) then in a tenuous convoluted way Go has &amp;lsquo;innovated&amp;rsquo; by avoiding that trend.&lt;/p&gt;

&lt;h2 id=&#34;go-is-an-innovative-thing:6f23aa5cf001e206affe126e84fac8b3&#34;&gt;Go is an Innovative Thing&lt;/h2&gt;

&lt;p&gt;It is hard to define what the &amp;lsquo;thing&amp;rsquo; is, but it is quite a broad thing, I can&amp;rsquo;t fully say it is an approach, or a belief, or even &amp;lsquo;patterns and practices&amp;rsquo;, though that last phrase feels closest. This is still about the best read on the subject: &lt;a href=&#34;https://talks.golang.org/2012/splash.article&#34;&gt;Go at Google: Language Design in the Service of Software Engineering&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Possibly Go&amp;rsquo;s greatest &amp;lsquo;innovation&amp;rsquo; is to eschew making software engineering an overly academic process in daily practice, and to focus on improving the tools, speed, reliability and pure pleasure in &lt;strong&gt;delivering&lt;/strong&gt; and running things of value.&lt;/p&gt;

&lt;p&gt;Thats not to say that Go encourages you hack away without a sound foundation, quite the opposite, I think Go almost &lt;em&gt;requires&lt;/em&gt; you to have a good grasp of the fundamentals, to be an effective Go programmer. I would say that the simplicity and imperative style that Go encourages, tends to demand a greater underlying computer science knowledge than many other languages may expect. Having recently watched &lt;a href=&#34;https://www.youtube.com/watch?v=ClPIeuL9HnI&#34;&gt;Go at Google: Language Design in the Service of Software Engineering&lt;/a&gt; I think Katrina Owen echo&amp;rsquo;s this belief.&lt;/p&gt;

&lt;h3 id=&#34;unifying:6f23aa5cf001e206affe126e84fac8b3&#34;&gt;Unifying&lt;/h3&gt;

&lt;p&gt;I think one reasonable way of categorising all the things that make up delivering software products is into: &lt;em&gt;human&lt;/em&gt;, &lt;em&gt;operational&lt;/em&gt; and &lt;em&gt;technology&lt;/em&gt; factors, in that order of value. Go helps address some problems in all three areas but it is its influence over human and operational factors where it sets itself apart from other systems.&lt;/p&gt;

&lt;p&gt;Even as technologists we can&amp;rsquo;t help moving things into the &amp;lsquo;human&amp;rsquo; domains such as emotion and personalisation, most compilers don&amp;rsquo;t care about many of the things humans care about, but the language naturally becomes a very human thing.&lt;/p&gt;

&lt;p&gt;Go has learned from the experience of fractured communities and continual in-fighting amongst teams and has attempted to avoid debates that continue to rage in other languages that are 20+ years old. The early focus on idioms helped that. This approach comes from years of experience delivering in teams at scale, where the language is one small factor, which has caused an inappropriate amount of time wasted on a tiny fraction of the whole value. As an example: curly brace positioning is one of the most trivial things possible, and yet still many hours are wasted on it.&lt;/p&gt;

&lt;h3 id=&#34;paradox-of-choice:6f23aa5cf001e206affe126e84fac8b3&#34;&gt;Paradox of Choice&lt;/h3&gt;

&lt;p&gt;In all languages there are always some basic primitives and data types that relate closely to the machine instruction set, which in turns map well to the hardware (see Note 1.) Ultimately all other higher order data structures in all languages are composed of arrays, references, and structs. Trees, heaps, sets, queues and everything else effectively only manipulate arrays of structs/primitives or self referencing structs, thats it, simple, or it should be.&lt;/p&gt;

&lt;p&gt;In the Go language at its heart that simplicity is encouraged, we are only offered some basics. To start with we are given primitives, structs and arrays, then because it is unavoidably useful we have a dynamic array, a slice which is an embellished array to allow dynamic resizing. Finally, in certain problem domains the power and flexibility of a hash-map is also unavoidable, therefore Go provides a Map built in.&lt;/p&gt;

&lt;p&gt;There is a subtlety to providing only this subset. The fact they map well to lower layers imbues an immediate sense of being more intimate with the CPU, which certainly for &amp;lsquo;older&amp;rsquo; engineers feels refreshing, and at a minimum for younger engineers tends to influence design decisions towards simplicity. Having said that the desire to construct complex implementations of data structures - even if used only once - is ever present when a new arrival to Go finds their favourite container is &amp;lsquo;missing&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;To provide any solution in Go that needs a dynamic data structure you can choose between hand rolled linked structures or a &lt;code&gt;Slice&lt;/code&gt; or &lt;code&gt;Map&lt;/code&gt; (or compose with them). As they are quite different the choice is normally obvious. Contrast this to the choice between map, set, hashset, bag etc etc, or rolling your own in a language that makes this a lot harder. Often the author actually only uses a subset of the functionality of those data structures. In these cases the choice becomes much less simple, indeed often a point of confusion and contention and can be the cause of further low-value conversations.&lt;/p&gt;

&lt;p&gt;A Go programmer takes a slice or map and mixes in a few functions to provide the structure they need. For example The Go standard library has provided a minimal &lt;code&gt;container&lt;/code&gt; package with a &lt;code&gt;heap&lt;/code&gt; (which is just an interface), a &lt;code&gt;list&lt;/code&gt; (doubly linked), and a &lt;code&gt;ring&lt;/code&gt; (which is a closed doubly linked list).  To implement a heap - you need to provide a builtin to implement the storage with an array being the typical choice.&lt;/p&gt;

&lt;p&gt;Each one of those packages has no more than around 200 lines of code. Those few lines of code are very readable, the behaviour understandable, and the performance predictable; being a function of the performance of the well understood builtin and the users own implementation code.&lt;/p&gt;

&lt;p&gt;This removal of choice and focus on reusing the two builtins, drives a readability, clarity and consistency amongst Go programmers, not afforded in other languages.&lt;/p&gt;

&lt;p&gt;In other languages an iterator (one of the often complained about omissions) necessarily abstracts that which is being contained, and often insists on a broad interface some of which then remains unused, and adds some cognitive load, sometimes unnecessarily.  Not providing an iterator and not providing many containers implementing iterable, or whatever other system, avoids needing a whole swathe of knowledge, indirection, discussion and misunderstanding, at little real world cost.&lt;/p&gt;

&lt;p&gt;The effect of the omission in real world code results in minimal extra work at code creation time, for great gains in the rest of the lifecycle. Custom data structures can be composed from the well understood builtins, rolled in under 100 lines of code and can can exist close to the place they are used (yes repeated!). The effect of this approach on readability, maintainability, decoupling, removing seemingly endless low value conversations, and when push comes to shove the ability to understand performance characteristics and then tune them, adds so much more value to the whole lifecycle, than the cost of the omission.&lt;/p&gt;

&lt;p&gt;These are subtle yet important factors that attempt to address some of the human and operational complications.&lt;/p&gt;

&lt;h2 id=&#34;more-than-a-language:6f23aa5cf001e206affe126e84fac8b3&#34;&gt;More Than a Language&lt;/h2&gt;

&lt;p&gt;Without going into all of the things that the Go ecosystem brings to the table on top of the language design, what should be clear from a shallow familiarity with the tooling is that Go has focussed on providing answers to some of the more difficult aspects of actually getting code that is both stable and agile into production. These things that were part of Go from the beginning have had to evolve over decades in other languages, often in fractured directions - again adding the paradox of choice. For example Go&amp;rsquo;s dependancy management attempts to solve a thorny problem, and while &lt;code&gt;go get&lt;/code&gt; in particular is going through some teething pains, its inclusion from day one is illustrative of Go’s intention.&lt;/p&gt;

&lt;p&gt;It is this focus on the operational aspects of development, so early on in Go&amp;rsquo;s evolution that emphasises the reason Go was created, and is commonly overlooked in favour of low value critiques of the language itself.&lt;/p&gt;

&lt;h3 id=&#34;note-1:6f23aa5cf001e206affe126e84fac8b3&#34;&gt;Note 1.&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;In our Von Neumann world we have basically three hardwired data structures, a register, a stack, and addressable memory, these are mapped via the instruction set to: register operations; effectively push and pop, moving data to and from memory addresses, and in CISC&amp;rsquo;s contiguous memory operations, even in RISC&amp;rsquo;s loop primitives are optimised for contiguous ranges. Ultimately these in turn map through compilers to value variables (which indirect the decision to use registers, the stack, or an addressable value), and reference variables, which contain the value of an address of the value, and slightly higher up the conceptual scale: arrays. Compilers also compose these fundamental variables into primitive data types: ints, floats, and arrays into strings etc. Finally, also through well managed contiguous memory, namely &amp;lsquo;packing’, common primitives are grouped into &amp;lsquo;structs&amp;rsquo;. There are subtle variations on these themes, particularly with respect to structs or objects, involving further indirection (think v-tables etc), but that is the crux of it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Test Pyramid and Availability Bias</title>
      <link>http://danmux.com/posts/test_pyramid_availability_bias/</link>
      <pubDate>Mon, 21 Dec 2015 00:00:00 UT</pubDate>
      
      <guid>http://danmux.com/posts/test_pyramid_availability_bias/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://www.mountaingoatsoftware.com/blog/the-forgotten-layer-of-the-test-automation-pyramid&#34;&gt;The test pyramid&lt;/a&gt; has its place - it gets across a simple idea, but it has been taken too literally, and applied innapropriately.&lt;/p&gt;

&lt;h2 id=&#34;the-pyramid-and-dificult-compromises:f9c27430fb20a304ea9dd81fcf7df4c9&#34;&gt;The Pyramid and Dificult Compromises&lt;/h2&gt;

&lt;p&gt;My understanding of Cohns original article was that people too often downplay the service or integration tests, and I think discussions of the pyramid miss this emphasis, and have focused too much on the Pyramid itself.&lt;/p&gt;

&lt;p&gt;Unit vs X Tests (where X = any name for anything other than Unit)  must be the most tiresome debate ever in the history of software development. Over the years I have often found myself encouraging and sometimes justifying my compromises. My arguments have never been devastatingly good, because like any engineering there are often many good enough ways to achieve the desired outcome.&lt;/p&gt;

&lt;p&gt;&amp;lsquo;Good enough&amp;rsquo; is at the heart of all engineering. Good enough to manage the risks with just enough confidence. From past experience I have, in general, found that developers from a computer science background sometimes struggle with &amp;lsquo;engineering compromise&amp;rsquo; more than those from an engineering background.&lt;/p&gt;

&lt;p&gt;Judging good enough and risk is hard and takes confidence and experience to get the balance right in the many different projects and products we work within. A set of tried and tested prescriptions is always more straight forward.&lt;/p&gt;

&lt;h2 id=&#34;the-base-of-the-pyramid-problem:f9c27430fb20a304ea9dd81fcf7df4c9&#34;&gt;The Base of the Pyramid Problem&lt;/h2&gt;

&lt;p&gt;It is way too prescriptive:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It oversimplifies the situation, so it is used as a crutch to avoid critical thinking (notice I avoided the phrase containing the word &amp;lsquo;cargo&amp;rsquo;). How often would 70:20:10 be perfect for your situation.&lt;/li&gt;
&lt;li&gt;The top of the pyramid refers explicitly to GUI based tests, often irrelevant, often the people who mention it forget this. (However, even a testing trapezoid would still be wrong)&lt;/li&gt;
&lt;li&gt;True user testing is completely ignored - experience - emotion - engagement (Dare I say quality as &lt;a href=&#34;https://en.wikipedia.org/wiki/Zen_and_the_Art_of_Motorcycle_Maintenance&#34;&gt;Persig&lt;/a&gt; defines it &amp;ldquo;Quality is the knife-edge of experience, found only in the present, known or at least potentially accessible to all of us&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;It is based on the false assumption that integration tests are slow and flaky, they can be as fast and robust as unit tests.&lt;/li&gt;
&lt;li&gt;It is 4 years old - the world has turned. Modern GUI&amp;rsquo;s (think Mobile and &lt;a href=&#34;https://en.wikipedia.org/wiki/Single-page_application&#34;&gt;SPA&lt;/a&gt;) are almost always cleanly divided by a well defined API. (if not then it&amp;rsquo;s not a testing problem, but a design problem)&lt;/li&gt;
&lt;li&gt;It downplays the relevance of boundary interactions, particularly during concurrency.&lt;/li&gt;
&lt;li&gt;Unit tests are subject to availability bias - and take on an inflated importance because of it.&lt;/li&gt;
&lt;li&gt;Unit tests themselves are a kind of availability bias - because they are easy to write and run they are used in the place of a more difficult, more complex, more valuable strategy, one that only becomes clear when you critically assess the real risks affecting quality.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;an-illustration-of-broken-thinking:f9c27430fb20a304ea9dd81fcf7df4c9&#34;&gt;An Illustration of Broken Thinking&lt;/h2&gt;

&lt;p&gt;The article most cited to me is the well read &lt;a href=&#34;http://martinfowler.com/bliki/TestPyramid.html&#34;&gt;Test Pyramid&lt;/a&gt; by Martin Fowler which references the original Mike Cohn article, &lt;a href=&#34;https://www.mountaingoatsoftware.com/blog/the-forgotten-layer-of-the-test-automation-pyramid&#34;&gt;The Forgotten Layer of the Test Automation Pyramid&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Martins post links to another well known supporting article from the Google Testing Blog with the deliberately captivating title&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://googletesting.blogspot.ch/2015/04/just-say-no-to-more-end-to-end-tests.html&#34;&gt;Just Say No to More End-to-End Tests&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Which captures the narrow experiences and environment of one setup with some fundamental problems. Some parts of that Google testing blog post I simply did not fully understand until a few re-reads, and even then I was left questioning the validity of what I read. I felt it sounded outdated, and was based on some strange assumptions, it appears I am not alone.&lt;/p&gt;

&lt;p&gt;A counterpoint is posted on Martin’s post, which is also worth reading: &lt;a href=&#34;https://www.symphonious.net/2015/04/30/making-end-to-end-tests-work/&#34;&gt;Making End-to-End Tests Work&lt;/a&gt; which succinctly points out some limitation of the test system mentioned in the Google testing blog post above&amp;hellip;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;If your idea of fantastic test infrastructure starts with the words “every night” and ends with an email being sent you’re doomed&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The Google post is further analytically &lt;a href=&#34;http://bryanpendleton.blogspot.com.au/2015/04/on-testing-strategies-and-end-to-end.html?m=1&#34;&gt;dismembered here&lt;/a&gt;, and this article captures my own confusion well&amp;hellip;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Whatever went wrong with this project, though, one thing is very clear to me:&lt;/p&gt;

&lt;p&gt;The testing strategy is not the problem here.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;detail-of-availability-bias:f9c27430fb20a304ea9dd81fcf7df4c9&#34;&gt;Detail of Availability Bias&lt;/h2&gt;

&lt;p&gt;(my own pseudo science - feel free to skip to next section (but there is mention of interesting work in any case))&lt;/p&gt;

&lt;p&gt;Recently I have been reading a fascinating book that has long been on my to-read list: &lt;a href=&#34;http://www.amazon.co.uk/Thinking-Fast-Slow-Daniel-Kahneman/dp/0141033576&#34;&gt;Kahneman&amp;rsquo;s Thinking Fast and Slow&lt;/a&gt;. Fortuitously Kahneman has gifted me another tool in my arsenal against the over valuing of unit tests. Availability bias.&lt;/p&gt;

&lt;p&gt;The over importance of unit testing may just be down to availability bias.&lt;/p&gt;

&lt;p&gt;When I analyse the past encounters over the issue of unit testing vs other types of testing, I suspect this bias (or availability heuristic as it is also known) may be the main factor that tips the balance in favour of unit tests and has resulted in them appearing to be so important.&lt;/p&gt;

&lt;p&gt;Whilst I can&amp;rsquo;t do the book justice here, I&amp;rsquo;ll try and capture the salient points. Availability bias is an example of many evolutionary shortcuts in the human mind that can substitute a simple emotional decision for an otherwise difficult complex one, and has been demonstrated in many, brilliant, simple psychological experiments.&lt;/p&gt;

&lt;p&gt;In particular, according to Kahneman, Norbert Schwarz showed the paradox that we are less confident in our decision when asked to come up with more reasons why it is a good decision. Our brains make an overconfident emotional decision when we can immediately produce a few supporting reasons, and a less confident decision, when forced to think harder. This is one of those paradoxes which are obvious when pointed out.&lt;/p&gt;

&lt;p&gt;The book goes onto describe some related effects, regarding risk, which triggered my connection with testing, because I think much more in terms of risk than of test type, or test metric. Research by Paul Slovic, Sarah Lichtenstein and Baruch Fischhoff Showed that scientists opinions on the benefits of a particular technology could be increased by downplaying the risks, and similarly that the perception of the risks of a technology would be decreased, just by describing the benefits.&lt;/p&gt;

&lt;p&gt;It is clear how this emotional bias can be applied to software testing:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;A lack of unit tests most often described as (and can be) a risk - therefore the benefits of unit tests are exaggerated in our minds.&lt;/li&gt;
&lt;li&gt;We can quickly recall a few examples of people who repeat the advantages of unit tests, and quickly recall a few personal experiences that support their advantage so the risks of focussing on them are downplayed.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is all based in normal animal survival laziness - it takes energy for our deep thinking brain to engage.&lt;/p&gt;

&lt;p&gt;A more direct consequence of our natural laziness also has a different type of biasing effect on the increased value attributed to unit testing.&lt;/p&gt;

&lt;p&gt;It is hard for anyone deeply embedded in a development team to truly know how valuable the team is, or, where necessary, how valuable individual members of the team are, or even how good the product is. The situation has developed where the very people responsible for the success of a development team are some of the least likely to be able to make an objective decision. Under these conditions it is easy to see how &amp;lsquo;measurement&amp;rsquo; is needed, it is this natural laziness that allows easy measurements to become so influential.&lt;/p&gt;

&lt;p&gt;Unit tests are easy, and the quick visibility they afford in the form of the second most harmfull metric in development - coverage, creates something measurable. This is an easy metric, and when coupled with the biases of 1 and 2 above it is easy to see how unit testing and test coverage take on a an overly exaggerated value. Perhaps most often outside of the team who writes the tests.&lt;/p&gt;

&lt;p&gt;I also think it is likely that we are still suffering the rebound from 10 years ago when test automation and unit testing were much less an integral part of the development cycle. The easiest goto tool in the interim has been the unit test.&lt;/p&gt;

&lt;h2 id=&#34;the-smart-way:f9c27430fb20a304ea9dd81fcf7df4c9&#34;&gt;The Smart Way&lt;/h2&gt;

&lt;p&gt;Whilst this post actually started out as a document of my linking availability bias with the over emphasis on unit testing and was not meant to be about the value of various tests in practice, it is probably clear that I encourage a more individually considered approach, than a set of prescribed rules.&lt;/p&gt;

&lt;p&gt;I want to make it clear that I totally understand that there are loads of cases, particularly on the computer science focussed side of development where unit tests are essentially the only sensible test strategy. But they are only one part of the package, and often a small part.&lt;/p&gt;

&lt;p&gt;In this article: &lt;a href=&#34;http://www.joecolantonio.com/2015/12/09/why-the-testing-pyramid-is-misleading-think-scales/&#34;&gt;Why the Testing Pyramid is Misleading&lt;/a&gt; the author discusses Todd Gardners (TrackJs) views which could be concieved to be indirectly addressing availability bias of unit tests, by making the point that we tend to not think in terms of risk. This article resonates strongly with my own approach to quality (again where quality is typically a bigger thing than that which we normally test for)&lt;/p&gt;

&lt;p&gt;That article references the video offering very sensible advice from Todd Gardner, Software Engineer and Entrepreneur at TrackJS, namely think critically&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://vimeo.com/144684986&#34;&gt;Case Studies in Terrible Testing&lt;/a&gt;
(slide deck &lt;a href=&#34;http://www.slideshare.net/todd3091/case-studies-in-terrible-testing&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Especially salient is the advice from 25 minutes on, though this picture of the relative importance of different testing to mitigate the scale of the risks to the success of one particular project should illustrate the main thrust of the presentation&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh3.googleusercontent.com/-uyf9z1SiSgw/Vnft1EYuFaI/AAAAAAAAMlQ/j_PQhbHL-jI/w1167-d-h870-p-rw&#34; alt=&#34;testing scales&#34; title=&#34;Testing Scales&#34; /&gt;

&lt;em&gt;Figure 1. A custom set of sliding scales of differing test strategies&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When we truly think about how we can best reduce the risk to success, and use alternative appropriate tools to manage that risk we start to focus more on delivering real value.&lt;/p&gt;

&lt;p&gt;Monitoring, CD, and a real understanding of the users perceived value or quality through canary code, A/B testing and the like will have a much bigger impact than 70% coverage.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Fast to fix is almost as good as never broken (and sometimes better)&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;(from Todd’s slides above)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The ‘scales of risk’ metaphor is much more intelligent and appropriate than the pyramid. The pyramid is one combination of the risk scales which may well align with a correct assignment of risk in a minority of real world cases (as would the ice cream cone). Though as far as I remember, not on any projects I have worked on.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Queues Are Not Always The Answer</title>
      <link>http://danmux.com/posts/queues-are-not-always-the-answer/</link>
      <pubDate>Mon, 20 Jul 2015 17:02:07 BST</pubDate>
      
      <guid>http://danmux.com/posts/queues-are-not-always-the-answer/</guid>
      <description>

&lt;p&gt;I feel developers reach for the queue all too quickly. I’m talking about stand alone message queue services like RabbitMQ, ActiveMQ etc. etc. Not an in memory data structure (which in fact can be all you need sometimes)&lt;/p&gt;

&lt;h2 id=&#34;sync-or-queue:eb0f6f06ad8a7448f62939e06ec5d67a&#34;&gt;Sync or Queue&lt;/h2&gt;

&lt;p&gt;Often the reasons for choosing a queue include many features that any synchronous service could provide.&lt;/p&gt;

&lt;p&gt;There are, in my opinion, only four compelling use cases for a queue over a simple remote service.&lt;/p&gt;

&lt;p&gt;This &lt;a href=&#34;http://blog.iron.io/2012/12/top-10-uses-for-message-queue.html&#34;&gt;blog post from Iron.io&lt;/a&gt; is a good example of an article that whilst explaining why queues are good never mentions where a simple service would suffice.&lt;/p&gt;

&lt;p&gt;All the reasons they mention as to why queues are good are correct. I just want to remind (myself mainly, so I can reference it when I get challenged again as to why I have not suggested a queue) that most of the advantages they mention are not exclusive to queues.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Decoupling&lt;/strong&gt; - Provides consistent interface, but then so do flexible payload interfaces. Admittedly a queue can allow the freedom to attach an number of subscribers without the publisher needing any further knowledge.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Redundancy&lt;/strong&gt; - not really redundancy, but retry in upstream failure. Retry is a great feature, which is also often present in other interfaces. Often queues are hard to cluster for redundancy.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Scaleability&lt;/strong&gt; - Queues support scaleability because of decoupling and ease of adding pub sub nodes to the queue - just the same effect as the decoupling delivered by an interface to any other out of process service.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Elasticity &amp;amp; Spikability&lt;/strong&gt; - the major use case  for queues - impedance miss-match&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Resiliency&lt;/strong&gt; - This argument assumes ALL processing nodes fail, otherwise it would just be the same behaviour as dealing with spikes (lack of cycles to process the work). This approach to ‘resiliency’ does not handle the case where the user is expecting feedback from the result of the request, then the queue lets them down.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Delivery Guarantees&lt;/strong&gt; - is not an advantage of queues - it needs to be stated because it feels like queues may not deliver messages - a direct interface, being synchronous, has an implicit delivery ‘guarantee’&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ordering Guarantees&lt;/strong&gt; - this can be a a valid use case if multiple processes feed into a queue, and assuming the queue itself is cluster-able, and has cross cluster atomic behaviour, then a queue, could be made to act like a temporal ordering funnel, in some way collating requests in a particular order (within an agreed time window). In any distributed system at scale, the clients of the queue are unlikely to deliver messages to the queue in a temporally deterministic order thereby undermining the queue value for this feature. Event ordering across a distributed cluster is THE hard problem in distributed systems, queues may inject some order into some parts of the system.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Buffering&lt;/strong&gt; - a duplication of the Elasticity feature, and again a way of dealing with impedance mismatch - if any consuming processes behind an interface can operate in parallel and at different lifetimes then the same effect is achievable without a queue.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Understanding data flow&lt;/strong&gt; - an argument for visibility, also solved by a consistent set of api’s in a system that are able to be reported on for statistics.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Asynchronous Communication&lt;/strong&gt; - probably the single biggest most valuable use case - if the instigating process does not care directly about the outcome, or can check the outcome later, and the system still needs some eventually consistent guarantees then the queue is a fine choice. example use cases: event based features like triggering an email, or streaming into a reporting system&lt;/p&gt;

&lt;p&gt;I think the other major feature, not mentioned in the article, is that typically queues offer&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rich Routing or Distribution Model&lt;/strong&gt; - Fan out, topics etc etc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Security&lt;/strong&gt;
The other aspect of a queue that is not mentioned in that article is security. A subscriber makes a connection outbound to the queue, so an internally secure zone in your network can avoid allowing any inbound connections, and only ever connects out to the queue, which could be considered more secure. Others may argue that all this does is change the attack vector slightly to focus on compromising the queue itself, and is no more secure than available attacks on the network layers, I don’t know enough about that, but it feels more secure to me not allowing inbound connections.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bad UX&lt;/strong&gt;
Using a queue in any part of your architecture that affects the user experience is a risky compromise, which can often mask the underlying problem.&lt;/p&gt;

&lt;h2 id=&#34;summary:eb0f6f06ad8a7448f62939e06ec5d67a&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In summary use a queue, if you really don’t mind asynchronous or parallel work&amp;hellip;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;If you truly have no control over, or don’t care about the upstream service response times.&lt;/li&gt;
&lt;li&gt;If you have spikes in your requests, and you can’t cost effectively keep to a reasonable response guarantee, and you know you have enough spare capacity in the off peak to catch up.&lt;/li&gt;
&lt;li&gt;If you want to do some funky distribution of your messages (typically to many observers) particularly if you are not bothered about the result of any upstream subscribers work&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;If you agree that the pull model from a secure zone to a queue adds to your network security.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>JSON, Gzip, Snappy and Gob Across the Wire</title>
      <link>http://danmux.com/posts/across_the_wire_serialisation/</link>
      <pubDate>Sun, 21 Sep 2014 00:00:00 UT</pubDate>
      
      <guid>http://danmux.com/posts/across_the_wire_serialisation/</guid>
      <description>

&lt;p&gt;Coming from a background where memory and clock cycles were sparse, binary encodings have always held an appeal. Since then I’ve been told we have loads of compute power, ample cheap RAM and disk, and when the network is the bottleneck then, well, that is a good problem to have.&lt;/p&gt;

&lt;p&gt;Its one of those ages old occasionally heated debates&amp;hellip;.&lt;/p&gt;

&lt;p&gt;(&lt;em&gt;tl;dr&lt;/em&gt; almost always use gzipped JSON)&lt;/p&gt;

&lt;h2 id=&#34;serialising-for-wire-and-disk:5bca79e758a5b8ad0a0678190c2bd34b&#34;&gt;Serialising for Wire and Disk&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Much better to use a more debuggable human readable encoding and compress it in flight during transmission or storage&lt;/strong&gt;, after all browsers have native support and the performance benefits of binary formats are negligible. This is the crux of the argument for those in favour of verbose text based serialisations.&lt;/p&gt;

&lt;p&gt;I understand the argument and &lt;strong&gt;this is almost always sound advice&lt;/strong&gt;, so why doesn’t Memcache do it, why do all NoSql and NewSql implementations offer a binary alternative if not &lt;em&gt;only&lt;/em&gt; a binary inerface? Why does Thrift thrive, and MessagePack pack a punch :p ?&lt;/p&gt;

&lt;p&gt;Is it faster, or is it just cooler to do some binary stuff? - ‘Intellectual masturbation’ as an old learned colleague delightfully coined it. Or is there really a compelling use case for these things.&lt;/p&gt;

&lt;p&gt;Heres a &lt;a href=&#34;https://groups.google.com/forum/#!topic/golang-nuts/xtXh0yWOens&#34;&gt;recent example of the debate&lt;/a&gt; with all the typical (valid) points being trotted out&lt;/p&gt;

&lt;h2 id=&#34;in-this-case:5bca79e758a5b8ad0a0678190c2bd34b&#34;&gt;In This Case&amp;hellip;&lt;/h2&gt;

&lt;p&gt;Having just built a nicely homogenous #golang rpc microservices framework (or ‘milliservices’ as &lt;a href=&#34;https://twitter.com/iand/status/510090898269831170&#34;&gt;Ian Davis called his&lt;/a&gt;) I was naturally drawn to the native RPC gob encoding, but I hedged my bets and did the second worst of both worlds a gob based RPC envelope - with a []byte payload that could carry any serialisation - a la http. (the absolute worst would be http, with a gob body)&lt;/p&gt;

&lt;p&gt;The point of this ‘neither one nor the other’ design was that much like HTTP the envelope is standard so all our components can speak the same language, output consistent log data and generally behave in a more homogenous way than you typically find in a mixed bag of microservices - what you put in the message payload is down to you and your services, of course for our internal systems gob is the natural choice for the payload as well.&lt;/p&gt;

&lt;h2 id=&#34;some-trivial-calculations:5bca79e758a5b8ad0a0678190c2bd34b&#34;&gt;Some Trivial Calculations&lt;/h2&gt;

&lt;p&gt;I did some initial calculations and benchmarking comparing gzipped JSON to ‘snappy’ JSON to raw gob. I suppose it would be useful to include lz4, but as far as I can tell snappy is not a million miles different.&lt;/p&gt;

&lt;p&gt;The data is a pretty tabular in format being lists of (300 ish) financial transactions, so naturally this does not favour normal JSON which repeats the ‘column’ names, however compressing virtually removes this disadvantage.&lt;/p&gt;

&lt;p&gt;The original data contained mainly text data, which does not favour binary.&lt;/p&gt;

&lt;p&gt;I understand that without the example data and code this is unscientific, as it is impossible to reproduce, and therefore can be read only as a hint of what the truth may be. If there were any more interest than myself making notes for me then I could do a proper job later.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Raw Gob&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Raw Json&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Gzipped Json&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Snappied Json&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Size  (bytes)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;72111&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;252512&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;27115&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;47271&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Size (xGob)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.38 (/2.66)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.66 (/1.53)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Decode Speed  (ns/op)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1453910&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1750450&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3557621&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3011828&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Decode Speed (xGob)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.83 (/1.2)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.41 (/2.45)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.48 (/2.07)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;xGob = multiplier of the Gob figure&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This data is for the payload or body only, whic relates to storage size (minus keys and indexes).&lt;/p&gt;

&lt;p&gt;If HTTP is used as the transport protocol then the average 300-500 bytes of HTTP header should be taken into account when considering bandwidth, though with internal systems this would be more like 100-200 bytes.&lt;/p&gt;

&lt;p&gt;Header size becomes a profound factor when transporting small payloads, making TCP a smarter choice, but then introducing similar debugging issues as faced with binary encodings.&lt;/p&gt;

&lt;p&gt;Our internal gob header is typically 40-50 bytes (mainly being the 36 byte text representation of &lt;a href=&#34;http://tools.ietf.org/html/rfc4122&#34;&gt;uuid&lt;/a&gt;, which would be better passed round as the raw 16 bytes)&lt;/p&gt;

&lt;p&gt;For a 40 byte binary payload (an array of 20 &lt;code&gt;int16&lt;/code&gt;&amp;rsquo;s for example) HTTP could easily cost 10x more bandwidth than TCP.&lt;/p&gt;

&lt;p&gt;The summary comparison to gob for our large data (remember this is a sub optimal use case for binary) is&amp;hellip;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Gzipped Json&lt;/td&gt;
&lt;td&gt;2.5x slower&lt;/td&gt;
&lt;td&gt;2.7x smaller&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Snappy Json&lt;/td&gt;
&lt;td&gt;2x slower&lt;/td&gt;
&lt;td&gt;1.5x smaller&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Uncompressed Json&lt;/td&gt;
&lt;td&gt;1.2x slower&lt;/td&gt;
&lt;td&gt;3.5x bigger&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;So even with binary unfriendly large text data its hard to strike a better balance than plain gob. If raw space and bandwidth were the primary concern then I would &lt;strong&gt;go for gzipped JSON over TCP&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I’m surprised how sluggish Snappy is. Others have &lt;a href=&#34;https://groups.google.com/forum/#!topic/golang-nuts/7T1AKfDAOcQ&#34;&gt;reported&lt;/a&gt; the pure Go implementation to be quite slow.&lt;/p&gt;

&lt;p&gt;None of the decoding benchmarks streamed the data - new encoders were made every loop, I know Gob would be even faster with this optimisation, all decoders decoded into an &lt;code&gt;interface{}&lt;/code&gt;, they would all have been quicker if a particular &lt;code&gt;struct&lt;/code&gt; was used.&lt;/p&gt;

&lt;h2 id=&#34;testing-binary-payloads:5bca79e758a5b8ad0a0678190c2bd34b&#34;&gt;Testing Binary Payloads&lt;/h2&gt;

&lt;p&gt;It is tempting to emphasise the more tangible representation of test data that a browser or even a prettified curl output offers, or the ease of editing a JSON file.&lt;/p&gt;

&lt;p&gt;It is only marginally more hassle to construct test structs (or the equivalent in your own language) in unit or integration tests, and in general a better idea, and something you’ll have to do anyway.&lt;/p&gt;

&lt;p&gt;In many languages (particularly Go) writing a curl like tool to interact with a binary rpc is, admittedly a tooling up overhead, however its a pretty simple, one off days work.&lt;/p&gt;

&lt;h2 id=&#34;summary:5bca79e758a5b8ad0a0678190c2bd34b&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;A compressed text based encoding like JSON &lt;strong&gt;is&lt;/strong&gt; more widely supported, quite compact and easier to test and debug, particularly if the consumer is a web browser.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Very few scenarios justify anything other than compressed JSON&lt;/strong&gt; (swap JSON with XML if you are stuck in that particular hell)&lt;/p&gt;

&lt;p&gt;If you are approaching or know you will approach network limitations, or will save £1000’s per month (substitute for your own acceptable budget) and want to keep response rates up then a binary format may well be the right choice for all payload sizes.&lt;/p&gt;

&lt;p&gt;If your system chatters lots of small chunks of data with a high ratio of none text to text data, at very high message rates, then a binary encoding particularly over TCP (thereby avoiding the HTTP header overhead) is by far the more sensible choice.&lt;/p&gt;

&lt;p&gt;Testing and debugging binary protocols is not as bad as people make out, and should not be a massively deciding factor.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Jmeter is a Poor Choice for REST and Golang</title>
      <link>http://danmux.com/posts/jmeter_rest_golang/</link>
      <pubDate>Sun, 06 Jul 2014 00:00:00 UT</pubDate>
      
      <guid>http://danmux.com/posts/jmeter_rest_golang/</guid>
      <description>

&lt;p&gt;Its essential we have good integration tests and performance tests on our restful api, particularly now that many of the moving parts will migrate to microservices written in Go.&lt;/p&gt;

&lt;p&gt;Trying to use Jmeter both to validate responses and apply reasonable load has been troublesome.&lt;/p&gt;

&lt;h2 id=&#34;json-requests-are-hard:b02f6e156d0f66f8b442c69a9bfa839c&#34;&gt;JSON Requests are Hard&lt;/h2&gt;

&lt;p&gt;Jmeter is crap at constructing anything but static JSON.&lt;/p&gt;

&lt;p&gt;Just a quick search uncovers &lt;a href=&#34;http://beanshell.org/&#34;&gt;Beanshell&lt;/a&gt; - and it looks like hassle.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ubik-ingenierie.com/blog/extract-JSON-content-efficiently-with-jmeter-using-JSON-path-syntax-with-ubik-load-pack/&#34;&gt;This alternative&lt;/a&gt; doesn&amp;rsquo;t look too much better.&lt;/p&gt;

&lt;h2 id=&#34;json-responses-are-hard:b02f6e156d0f66f8b442c69a9bfa839c&#34;&gt;JSON Responses are Hard&lt;/h2&gt;

&lt;p&gt;Applying meaningful assertions to the responses in Jmeter is also a bit of a ball ache - regex is the default. There is no json parsing out of the box.&lt;/p&gt;

&lt;p&gt;Plugins improve things somewhat, but modelling a flow of a couple of requests with some shared session awareness is another load of hassle.&lt;/p&gt;

&lt;h2 id=&#34;performance-is-questionable:b02f6e156d0f66f8b442c69a9bfa839c&#34;&gt;Performance is Questionable&lt;/h2&gt;

&lt;p&gt;My own experiments and the thread below shows how a single jmeter instance is probably not quick enough to test the performance of a Go based web server, without setting up a few instances - but i spose we will have to do that in production even if we do find a fast tool.&lt;/p&gt;

&lt;!-- Place this tag in your head or just before your close body tag. --&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;https://apis.google.com/js/plusone.js&#34;&gt;&lt;/script&gt;

&lt;!-- Place this tag where you want the widget to render. --&gt;

&lt;div class=&#34;g-post&#34; data-href=&#34;https://plus.google.com/101114877505962271216/posts/PeZk8FY3PWY&#34;&gt;&lt;/div&gt;

&lt;h2 id=&#34;alternatives:b02f6e156d0f66f8b442c69a9bfa839c&#34;&gt;Alternatives&lt;/h2&gt;

&lt;p&gt;A quick search shows&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://code.google.com/p/restty/&#34;&gt;Resty&lt;/a&gt; - not tried it, not sure it does performance testing.&lt;/p&gt;

&lt;p&gt;Others via stack overflow etc. all appear to be pretty much GUI based or GUI only&lt;/p&gt;

&lt;h2 id=&#34;next-steps:b02f6e156d0f66f8b442c69a9bfa839c&#34;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;Do we build our own tests?&lt;/p&gt;

&lt;p&gt;Is there a more JSON friendly tool that can assert, pass on responses to the next step and load the service in parallel? I couldnt find anything.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=7995111&#34;&gt;Fancy discussing on HN&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Embedded Gists</title>
      <link>http://danmux.com/posts/embedded_gists/</link>
      <pubDate>Sat, 05 Jul 2014 00:00:00 UT</pubDate>
      
      <guid>http://danmux.com/posts/embedded_gists/</guid>
      <description>

&lt;h2 id=&#34;syntax-highlighting-or-embedded-gists:1344d5413a88f5694a6a670438370e1d&#34;&gt;Syntax Highlighting - or Embedded Gists&lt;/h2&gt;

&lt;p&gt;I was quite excited by the inline syntax highlighting that Hugo provides via the python plugin &lt;a href=&#34;http://pygments.org/&#34;&gt;Pygments&lt;/a&gt;. But also wanted to try embedding gists&lt;/p&gt;

&lt;p&gt;So here is an example&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34; style=&#34;background: #202020&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #d0d0d0&#34;&gt;&amp;lt;p&amp;gt;&lt;/span&gt;&lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #447fcf&#34;&gt;digit_sum&lt;/span&gt;&lt;span style=&#34;color: #d0d0d0&#34;&gt;(n):&lt;/span&gt;
    &lt;span style=&#34;color: #d0d0d0&#34;&gt;s&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;n:&lt;/span&gt;   &lt;span style=&#34;color: #999999; font-style: italic&#34;&gt;# while n is ‘truthy’ for an integer that means not 0&lt;/span&gt;
        &lt;span style=&#34;color: #d0d0d0&#34;&gt;s&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;s&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;(n&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color: #d0d0d0&#34;&gt;)&lt;/span&gt;   &lt;span style=&#34;color: #999999; font-style: italic&#34;&gt;# the sum is the sum + the remainder of dividing the incoming number (n) by 10  157 % 10 = 7&lt;/span&gt;
        &lt;span style=&#34;color: #d0d0d0&#34;&gt;n&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;n&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;10&lt;/span&gt;         &lt;span style=&#34;color: #999999; font-style: italic&#34;&gt;# n = the integer of n / 10   int(15.7) = 15&lt;/span&gt;
    &lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;s&amp;lt;/p&amp;gt;&lt;/span&gt;

&lt;span style=&#34;color: #d0d0d0&#34;&gt;&amp;lt;p&amp;gt;&lt;/span&gt;&lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;digit_sum(&lt;/span&gt;&lt;span style=&#34;color: #3677a9&#34;&gt;157&lt;/span&gt;&lt;span style=&#34;color: #d0d0d0&#34;&gt;)&amp;lt;/p&amp;gt;&lt;/span&gt;

&lt;span style=&#34;color: #d0d0d0&#34;&gt;&amp;lt;p&amp;gt;&lt;/span&gt;&lt;span style=&#34;color: #a61717; background-color: #e3d2d2&#34;&gt;”’&lt;/span&gt;
&lt;span style=&#34;color: #d0d0d0&#34;&gt;calling&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;digit_sum(&lt;/span&gt;&lt;span style=&#34;color: #3677a9&#34;&gt;157&lt;/span&gt;&lt;span style=&#34;color: #d0d0d0&#34;&gt;)&amp;lt;/p&amp;gt;&lt;/span&gt;

&lt;span style=&#34;color: #d0d0d0&#34;&gt;&amp;lt;h2&lt;/span&gt; &lt;span style=&#34;color: #24909d&#34;&gt;id&lt;/span&gt;&lt;span style=&#34;color: #d0d0d0&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #ed9d13&#34;&gt;&amp;quot;loop-s-n-n-10-n-10:1344d5413a88f5694a6a670438370e1d&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #d0d0d0&#34;&gt;&amp;gt;loop&lt;/span&gt;  &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;s&lt;/span&gt;   &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;n&lt;/span&gt;   &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;n&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;10&lt;/span&gt;  &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;n&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color: #d0d0d0&#34;&gt;&amp;lt;/h2&amp;gt;&lt;/span&gt;

&lt;span style=&#34;color: #d0d0d0&#34;&gt;&amp;lt;p&amp;gt;&lt;/span&gt;&lt;span style=&#34;color: #3677a9&#34;&gt;0&lt;/span&gt;     &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;0&lt;/span&gt;   &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;157&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt;   &lt;span style=&#34;color: #3677a9&#34;&gt;7&lt;/span&gt;     &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt;  &lt;span style=&#34;color: #3677a9&#34;&gt;15&lt;/span&gt;
&lt;span style=&#34;color: #3677a9&#34;&gt;1&lt;/span&gt;     &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;7&lt;/span&gt;   &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;15&lt;/span&gt;  &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt;   &lt;span style=&#34;color: #3677a9&#34;&gt;5&lt;/span&gt;     &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt;  &lt;span style=&#34;color: #3677a9&#34;&gt;1&lt;/span&gt;
&lt;span style=&#34;color: #3677a9&#34;&gt;2&lt;/span&gt;     &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;12&lt;/span&gt;  &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;1&lt;/span&gt;   &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt;   &lt;span style=&#34;color: #3677a9&#34;&gt;1&lt;/span&gt;     &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt;  &lt;span style=&#34;color: #3677a9&#34;&gt;0&lt;/span&gt;
&lt;span style=&#34;color: #3677a9&#34;&gt;3&lt;/span&gt;     &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;13&lt;/span&gt;  &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color: #3677a9&#34;&gt;0&lt;/span&gt;   &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&lt;/span&gt;         &lt;span style=&#34;color: #d0d0d0&#34;&gt;|&amp;lt;br&lt;/span&gt; &lt;span style=&#34;color: #d0d0d0&#34;&gt;/&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color: #a61717; background-color: #e3d2d2&#34;&gt;”’&lt;/span&gt;&lt;span style=&#34;color: #d0d0d0&#34;&gt;&amp;lt;/p&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;But then thought perhaps it is better to embed gists than have inline markup in blog posts then folk can fork the code and comment there.&lt;/p&gt;

&lt;p&gt;So on embedding a gist as follows (but without syntax highlighting) failed&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34; style=&#34;background: #202020&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;&amp;lt;script &lt;/span&gt;&lt;span style=&#34;color: #bbbbbb&#34;&gt;src=&lt;/span&gt;&lt;span style=&#34;color: #ed9d13&#34;&gt;&amp;quot;https://gist.github.com/danmux/042fa69bed3791afe658.js&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Putting it in another block partially worked&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34; style=&#34;background: #202020&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;&amp;lt;p&amp;gt;&lt;/span&gt;
    &lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;&amp;lt;script &lt;/span&gt;&lt;span style=&#34;color: #bbbbbb&#34;&gt;src=&lt;/span&gt;&lt;span style=&#34;color: #ed9d13&#34;&gt;&amp;quot;https://gist.github.com/danmux/042fa69bed3791afe658.js&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;&amp;gt;&lt;/span&gt;
    &lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color: #6ab825; font-weight: bold&#34;&gt;&amp;lt;/p&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;I was left with an unclosed script tag.&lt;/p&gt;

&lt;p&gt;A git of googling turned up this thread&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://groups.google.com/forum/#!topic/hugo-discuss/3GW56aMYQF8&#34;&gt;https://groups.google.com/forum/#!topic/hugo-discuss/3GW56aMYQF8&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and this pull request &amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/spf13/hugo/pull/305&#34;&gt;https://github.com/spf13/hugo/pull/305&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;which missed the latest release by a few days&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/spf13/hugo/releases/tag/v0.11&#34;&gt;https://github.com/spf13/hugo/releases/tag/v0.11&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So I went ahead an built the master head - from my fork (ya know just in case I can help)&lt;/p&gt;

&lt;p&gt;and added the script tag in&amp;hellip;.&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/danmux/042fa69bed3791afe658.js&#34;&gt;&lt;/script&gt;

&lt;h3 id=&#34;and-it-worked:1344d5413a88f5694a6a670438370e1d&#34;&gt;And it worked !&lt;/h3&gt;

&lt;p&gt;Nice work &lt;a href=&#34;https://github.com/jmitchell&#34;&gt;jmitchell&lt;/a&gt; and &lt;a href=&#34;https://github.com/spf13&#34;&gt;Steve Francia&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So gists it is for me&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Making Your Own Summary</title>
      <link>http://danmux.com/posts/hugo_summary/</link>
      <pubDate>Sat, 28 Jun 2014 00:00:00 UT</pubDate>
      
      <guid>http://danmux.com/posts/hugo_summary/</guid>
      <description>&lt;p&gt;Hugo allows you to specify where the summary stops - and allows the full markdown including shortcodes.&lt;/p&gt;

&lt;p&gt;You just need to construct the first bit of your article so that it makes a nice summary and then end it with&amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt; !--more--&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(of course dont include the space :) )&lt;/p&gt;

&lt;!-- here is the real more... --&gt;

&lt;p&gt;Everything after the more comment will not make it into the summary - sweet.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Moving to Hugo</title>
      <link>http://danmux.com/posts/hugo_based_blog/</link>
      <pubDate>Thu, 29 May 2014 00:00:00 UT</pubDate>
      
      <guid>http://danmux.com/posts/hugo_based_blog/</guid>
      <description>

&lt;p&gt;I decided that I should blog under my danmux.com domain - I often use danmux around the internet, sometimes danmull, but normally danmux for tech type things, so it makes sense.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;danmux&lt;/strong&gt; because the &lt;strong&gt;x&lt;/strong&gt; has always been a notable part of my name - and mux reminds me of my electrical engineering days, and I think humans multiplex all the time, there it is.&lt;/p&gt;

&lt;h2 id=&#34;github-pages:a25a3b4ce2b3a612bd067d9bd96cbf79&#34;&gt;Github Pages&lt;/h2&gt;

&lt;p&gt;As this will only get a couple of hits what could be better than hosting it on &lt;a href=&#34;https://pages.github.com/&#34;&gt;github pages&lt;/a&gt; - I&amp;rsquo;m a little bit in love with github anyway so perfect choice.&lt;/p&gt;

&lt;h2 id=&#34;hugo:a25a3b4ce2b3a612bd067d9bd96cbf79&#34;&gt;Hugo&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m a little bit in love with go - so &lt;a href=&#34;http://hugo.spf13.com/&#34;&gt;Hugo&lt;/a&gt; was the perfect choice as well, and its been great so far, other than is typical of newish open source projects slightly lacking in the documentation department.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Banks Love Hackers</title>
      <link>http://danmux.com/posts/banks_love_hackers/</link>
      <pubDate>Fri, 03 Feb 2012 00:00:00 UT</pubDate>
      
      <guid>http://danmux.com/posts/banks_love_hackers/</guid>
      <description>

&lt;p&gt;A recent BBC Click article reporting &lt;a href=&#34;http://www.bbc.co.uk/news/technology-16812064&#34;&gt;“Hackers outwit online banking identity security systems”&lt;/a&gt; show how ‘hackers’ can poison online banking web sites to trick customers into transferring money out of their accounts.&lt;/p&gt;

&lt;p&gt;Banks love this kind of article because if keeps their smoke screen smouldering.&lt;/p&gt;

&lt;p&gt;The article reports that…&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Online banking fraud losses totalled £16.9 million in the first six months of 2011, according to Financial Fraud Action UK.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Wow, thats a lot! The banks definitely need to get smarter about security. In fact it is a subject banks do like to talk about a lot. Whilst some bank have started to do more things to help protect these losses, most banks simply use ‘security concerns’ as another excuse to explain away the lack of banking innovation and why they have not improved customer engagement and ultimately consumer empowerment.&lt;/p&gt;

&lt;p&gt;The real news is that banks are still defrauding their customers to the tune of a few £billion a year. Putting the numbers into perspective, I was going to call this post..&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“Fraudsters dupe UK current account holders out of £2.6 Billion”.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-real-truth:29b4d8f37ceca4c7de5a5a33d1a60991&#34;&gt;The Real Truth&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;2011 Bank fraud in 2011:  £32 Million&lt;/li&gt;
&lt;li&gt;2006 Unpaid item Fees: £2,600 Million (81x)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These numbers are based on the &lt;a href=&#34;http://webarchive.nationalarchives.gov.uk/20140402142426/http:/oft.gov.uk/shared_oft/reports/financial_products/OFT1005exec.pdf&#34;&gt;OFT report from 2008&lt;/a&gt; – £2.6 billion in ‘unpaid item’ penaly charges during 2006 (there’s actually another £0.5billion in unauthorised overdraft fees as well). This number is probably now a tiny bit high. A more recent OFT report in 2010 show the average unpaid item fee has halved since the 2008 reports numbers, but when you factor in the other penalty fees, it won’t be far off.&lt;/p&gt;

&lt;p&gt;You know I wouldn’t be surprised if the banks didn’t like a little bit of fraud – especially if its online – then they can keep not delivering the services that would help many more people to avoid these (still) ridiculous fees and charges. I wonder if any banks have a secret ‘hacker department’ (btw I’m using hacker in the now more common ‘bad guy at a computer’ way. Not the original and (correct) meaning, as per Zuks recent misunderstood statement). Whilst the banks have cleaned up their act a bit – we must applaud them for halving the average penalty from £34 to £17 – the OFT report in 2008, provides some choice insight into why the banks like these sneaky, after the event, charges.&lt;/p&gt;

&lt;p&gt;The lack of visibility of insufficient funds charges to consumers has reduced the incentive for the banks to compete on these aspects. As a result some banks appear to see insufficient funds charges in particular as an attractive way to generate additional revenue without affecting demand for their accounts.&lt;/p&gt;

&lt;p&gt;A footnote goes into more detail: During the course of this market study, the OFT has seen banks’ internal documents on the level of charges that include statements such as:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;‘in order to maximise fee revenue, whilst maintaining our competitive position, selective increases in [insufficient funds charges] are proposed’,&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;‘Increasing [insufficient funds] charges will have less impact on our marketing position due to its lower visibility.’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note Well – that there is not a hint of this being ‘handling costs’, its not that the cost to service the un-arranged debt has gone up – simply that they could generate profit whilst hiding the cause!&lt;/p&gt;

&lt;p&gt;Its easy for high earners, and those that manage their accounts well to blame the individuals foolishness, but it is seriously easy to get caught out, almost everyone has been tripped up at one time or another. To get a feel or the scale of the problem (from the 2008 report).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;over a fifth of consumers were unaware of insufficient funds charges until they had incurred one.&lt;/p&gt;

&lt;p&gt;over 12.6 million accounts (23 per cent of active accounts) incurred at least one insufficient funds charge in 2006.&lt;/p&gt;

&lt;p&gt;those consumers who incurred an insufficient funds charge in 2006 were more likely to incur at least six charges than just one.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So why would banks not want to offer compelling online and mobile services to keep us well on top of our finances. Why would they not want to ‘be on our side’ and help us out with timely warnings and reminders, and quick emergency transfers?&lt;/p&gt;

&lt;p&gt;Well of course that would be a ‘security concern’.&lt;/p&gt;

&lt;p&gt;(by the way don’t worry about the banks not making enough money in this economic downturn &lt;a href=&#34;http://www.independent.co.uk/news/business/news/banks-profits-soar-as-interest-rates-rise-2219850.html&#34;&gt;&amp;lsquo;profits are soaring&amp;rsquo;&lt;/a&gt; )&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bank 1.5</title>
      <link>http://danmux.com/posts/bank_1_5/</link>
      <pubDate>Fri, 23 Sep 2011 00:00:00 UT</pubDate>
      
      <guid>http://danmux.com/posts/bank_1_5/</guid>
      <description>

&lt;p&gt;This past week saw two of the biggest banking and financial innovation conferences take place, Sibos and Finovate. On following a few Twitter streams of a few attendees, a new meme started to appear – possibly a bit premature to call it a meme and incorrect to call it new, but none the less the concept is valid if a bit bank-geeky.&lt;/p&gt;

&lt;p&gt;Borrowing from the Web 2.0 catchall or marketing label for anything more interactive than the static Web 1.0 but less linked than the evolving beb of data (Web 3.0?) the banking innovation consultant, speaker and author Brett King has coalesced thoughts and ideas around the next generation of consumer banking and published them in his popular book – Bank 2.0&lt;/p&gt;

&lt;h2 id=&#34;web-2-0:11f35b58cf248b7079c7bd8c599f0aaf&#34;&gt;Web 2.0&lt;/h2&gt;

&lt;p&gt;By borrowing the Web 2.0 concept, Bank 2.0 for those on the bank – web tech boundary conveys some immediate meaning.&lt;/p&gt;

&lt;p&gt;Using version numbers to try and capture a few ideas around something as amorphous as web technology soon led to various tongue in cheek references to Web 1.5 for half hearted attempts to wejazzle up web sites with a splash of ajax. There was a lot of talk of porcine cosmetics, and whilst the more hardcore Web 2.0 crowd exclaimed “you can’t polish a turd” – referencing the broken underlying technology, other more optimistic folk responded with “no, but you can roll it in glitter”&lt;/p&gt;

&lt;p&gt;I’ve no doubt that the glittering of the web detracted from the real shift that was taking place, possibly slowed and even damaged broader progress, but for a comercial business to stay current and competitive it was a fair transitionary compromise.&lt;/p&gt;

&lt;p&gt;The shift to Web 2.0 peaked around 10 years ago and began years before that and there is now a strongly swelling tide building to the the next wave of the web of linked data and of course mobile. The journey to bank 2.0 however only really started in 2005 when Aaron Patzer started working on Mint.com, and some US banks started rolling out some personal finance features.&lt;/p&gt;

&lt;p&gt;Banks are in the throws of the first phase of the journey – Banks are are rolling turds in glitter, they are at Bank 1.X (where 0 &amp;lt; X &amp;lt; 2) Some even say that banks have not even reached Bank 1.00 but we have to mark our datum somewhere.&lt;/p&gt;

&lt;p&gt;For the web to evolve into Web 2.0 it took a concerted global vertical technology stack refresh, from the improving hardware (thanks Moore) with httpd evolving to the more plug-able Apache through efficient (to code) programming languages through wider pipes with the growth in always connected broadband, up to Javascript (and the proprietary Flash), better home computing and tighter more open browsers.&lt;/p&gt;

&lt;h2 id=&#34;open-innovation:11f35b58cf248b7079c7bd8c599f0aaf&#34;&gt;Open Innovation&lt;/h2&gt;

&lt;p&gt;The reason that could happen so comparatively quickly – it was open. This is the very reason why Banks will not adopt the same path or pace. The seismic shift in the internet took billions of collaborative hours enabled by the nature of the internet itself and by the passion of the people to defend against any individual corporate land grab.&lt;/p&gt;

&lt;h2 id=&#34;tbl:11f35b58cf248b7079c7bd8c599f0aaf&#34;&gt;TBL&lt;/h2&gt;

&lt;p&gt;The banks have a similar scale problem to solve, but they dont have an open infrastructure, they dont have an inter-net, they have a large closed global intra-net curated by a cartel of self interested owners which is deeply rooted in and protected by the governments that helped create this razor wired garden. This situation isn’t all bad, and I dont know if there could have been a realistic alternative, or if there will be. Time will tell if a decentralised none homogenous system of many parts can unseat the incumbent system, if it can, it will take many more years. I suspect that the global legislative innovation antibodies may win this one. Though having said that there are some strong network effects at play here with telcos and social networks picking at openings.&lt;/p&gt;

&lt;p&gt;Bigger than all of this is perhaps the motivation for change, the internet changed because it was 10′s of thousands of people with a shared passion and vision that was well aligned with what the general public wanted, it was two sided, pull-pull, win-win. With Banks…meh!&lt;/p&gt;

&lt;h2 id=&#34;more-layers:11f35b58cf248b7079c7bd8c599f0aaf&#34;&gt;More Layers&lt;/h2&gt;

&lt;p&gt;The internet is shifting into the next phase where the technology stack is getting deeper – big internet companies are doing the heavy lifting and heavy investment to encourage an eco-system of impassioned organisms to symbiotically share their hard work – to build upon the work of the host – filling a multitude of difficult to reach customer niches, and importantly drive value into the host. Platform as a service – open web based API’s, Amazon web services, EC2, Azure, Google App Engine, force.com etc. etc. the list is endless and extremely lucrative.&lt;/p&gt;

&lt;h2 id=&#34;excellence-expected:11f35b58cf248b7079c7bd8c599f0aaf&#34;&gt;Excellence Expected&lt;/h2&gt;

&lt;p&gt;Apple, Amazon, Google, Facebook have driven customer expectation through the roof, particularly with respect to quality, and immediacy. What damage these pesky brilliant companies have done whilst delighting their customers! Do they realise how hard it is to hit the benchmark they have set. Do the banks realise their newer customers in particular expect no less!&lt;/p&gt;

&lt;p&gt;It is still true that the core banking systems need to continue to evolve and the technology refresh cycle needs to pick up for these encumbants to stay in the game, to compete or join the disruptors. That wall of legislative razor wire that constrains also protects, but time is running out.&lt;/p&gt;

&lt;p&gt;I think it is too late for banks to continue to own the whole vertical. It is too big too fast and too difficult. Consumer expectation is moving too fast for them to make the fundamental corporate attitude shifts required to fully engage with real customers the way every recent poster child startup has. Let the front end be owned by those that ‘get it’ look at what Bank Simple is about to do, I reserve judgement but am equally optimistic about MovenBank – both have chosen not to beat the banks at their own game but build on the existing banks core competency.&lt;/p&gt;

&lt;h2 id=&#34;towards-bank-2-0:11f35b58cf248b7079c7bd8c599f0aaf&#34;&gt;Towards Bank 2.0&lt;/h2&gt;

&lt;p&gt;Some Banks are starting the shift already – according to that Sibos and Finovate Twitter stream – Banking as a Service is on the way. Rather than Citi knocking the stuffing out of Bank 2.0 by releasing their payment API, they took a step towards enabling bank 2.0. Mastercard does it already. If the Banks are to thrive under this next wave they need to bend and work towards helping fulfil our expectations of Bank 2.0, they need to offer the next layer up even richer access to their services and data – I mean our data.&lt;/p&gt;

&lt;p&gt;We need them to loosen the grip, we need those API’s, we need Banking as a Service.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>